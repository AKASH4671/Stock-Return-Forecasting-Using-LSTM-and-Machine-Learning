# ðŸ“ˆ Stock Return Forecasting Using LSTM & Machine Learning

This project explores how machine learning â€” especially **Long Short-Term Memory (LSTM)** networks â€” can be applied to forecast short-term stock returns using historical lag features. It also compares traditional models like **Random Forest** and **XGBoost**, offering practical insights into their strengths and limitations.

> ðŸ“Š Blends concepts from AI, time-series forecasting, and financial return behavior  
> ðŸ§  Built to deepen practical understanding of sequential modeling in finance  
> ðŸ’¼ Reflects the intersection of data science and modern quantitative analysis

---

## ðŸ“Š Problem Statement

Can we forecast short-term **stock return movements** using only past return data (lagged features)?  
This simulates what many **quantitative models** in trading and portfolio construction attempt.

---

## ðŸŽ¯ Goals

- Predict next-day returns based on past patterns
- Compare performance of **tree-based models** vs. **deep learning**
- Build a reusable ML pipeline (scaling, saving, evaluation)
- Explore sequential modeling with LSTM for financial time series

---

## ðŸ“ Project Structure

| Folder        | Contents                                     |
|---------------|----------------------------------------------|
| `data/`       | Preprocessed stock data, predictions, scalers|
| `models/`     | Trained ML models (LSTM `.h5`, RF/XGB `.pkl`)|
| `notebooks/`  | Jupyter notebooks for each modeling approach |
| `docs/`       | Explanations with diagrams and code walkthroughs |

---

## ðŸ“¦ Models Used

| Model          | Highlights                                     |
|----------------|-----------------------------------------------|
| **Random Forest** | Fast, stable, and interpretable on tabular data |
| **XGBoost**        | Regularized boosting with strong tabular performance |
| **LSTM**           | Captures time dependencies, useful for sequence patterns |

```
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  Preprocessed CSV File   â”‚
               â”‚  (Lag_1, Lag_2, Lag_3)   â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ MinMaxScaler (X, y)â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Time Series Sequence Creation â”‚                                                 >> LSTM MODEL SHOWCASE <<
          â”‚  [samples, 5 days, 3 features] â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       
                 â”‚    LSTM Model      â”‚
                 â”‚(64 Units + Dropout)â”‚                                              
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Dense(1)   â”‚
                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Inverse Scaler (y) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  Predicted Return (Output) â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


---

## ðŸ“ˆ Performance Summary (on Tesla Returns)

| Model        | MAE      | RMSE     | RÂ² Score  |
|--------------|----------|----------|-----------|
| Random Forest| 0.03165  | 0.00191  | -0.0201   |
| XGBoost      | 0.03291  | 0.00208  | -0.1084   |
| LSTM         | 0.03226  | 0.04449  | -0.0545   |

> ðŸ“Œ **Insight**:  
> While LSTM is built for sequences, simpler tree-based models like Random Forest outperformed it here â€” possibly due to the limited input features (no volume, no technical indicators).
This shows the importance of feature richness in deep learning for finance.

---

## ðŸ”§ Why This Project is Finance-Relevant

- **Return Prediction** is central to:
  - Algorithmic Trading
  - Portfolio Optimization
  - Quantitative Research

- **LSTM** mimics trader behavior by using **memory across days**, unlike static models

- Reflects real industry practices:
  - Avoids data leakage by preserving sequence
  - Includes model saving & scaling pipelines
  - Evaluates models on unseen data

> This project demonstrates practical awareness of **modeling returns realistically**, not just achieving the lowest error.

---

## ðŸ›  How to Reproduce

1. Clone this repo
2. Use provided Tesla dataset or plug in your own return data
3. Run:
    - `random_forest_model.ipynb`
    - `xgboost_model.ipynb`
    - `lstm_model.ipynb`
4. Check predictions & visualizations

---

## ðŸ“š Documentation

All model decisions, diagrams, and preprocessing logic are fully explained in the `docs/` folder:

- LSTM input structure (3D)
- MinMaxScaler rationale
- Model saving with `joblib`
- Sequential data creation logic

---

## âœ… Summary

This project investigates **how machine learning can be applied to return forecasting**, a core problem in quantitative finance. It explores the pros and cons of different modeling approaches and builds a **clean, reproducible ML pipeline** for future use or extension.

---


